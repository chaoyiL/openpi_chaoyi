#!/usr/bin/env python3
"""
å°† ViTaMin-B Zarr æ ¼å¼æ•°æ®è½¬æ¢ä¸º LeRobot æ ¼å¼ï¼ˆä¼˜åŒ–ç‰ˆï¼šå†…å­˜é¢„åŠ è½½ + å¼‚æ­¥å†™å…¥ï¼‰
"""

import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
from threading import Thread
import sys
import os

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.append(project_root)

import zarr
from zarr.storage import ZipStore
import numpy as np
import cv2
from pathlib import Path
from tqdm import tqdm
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

# æ³¨å†Œå›¾åƒè§£ç å™¨
from utils.imagecodecs_numcodecs import register_codecs
register_codecs()
from utils.pose_util import pose_to_mat, mat_to_pose


class ZarrToLeRobotConverter:
    """ViTaMin-B Zarr æ ¼å¼åˆ° LeRobot æ ¼å¼çš„è½¬æ¢å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, 
                 zarr_path, 
                 output_repo_id, 
                 fps=30, 
                 state_dim=20, 
                 action_dim=20,
                 language_instruction=["perform bimanual manipulation task"]):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.zarr_path = Path(zarr_path)
        self.output_repo_id = output_repo_id

        if not self.zarr_path.exists():
            raise ValueError(f"Zarr æ–‡ä»¶ä¸å­˜åœ¨: {self.zarr_path}")
        
        # åŠ è½½ Zarr æ•°æ®
        print(f"åŠ è½½ Zarr æ•°æ®: {self.zarr_path}")
        store = ZipStore(self.zarr_path, mode="r")
        self.zarr_root = zarr.open_group(store=store, mode="r")
        self.data = self.zarr_root["data"]
        
        print(f"Zarr æ•°æ®åŒ…å«çš„é”®: {list(self.data.keys())}")

        # åˆ†æç»“æ„
        self.robot_keys, self.camera_keys, self.tactile_keys, \
        self.num_robots, self.num_cameras, self.num_tactiles = self.analyze_zarr_structure()

        # è·å–å›¾åƒå½¢çŠ¶
        self.img_size = (224, 224, 3)
        if len(self.camera_keys) > 0:
            first_camera_rgb = self._process_image(self.data[self.camera_keys[0]][0])
            self.img_size = first_camera_rgb.shape
        
        self.fps = fps
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.language_instruction = language_instruction
        
        # ğŸ”¥ é¢„åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
        self._preload_data()
        
        # å…³é—­ storeï¼Œé¿å…åç»­è®¿é—®
        if hasattr(self.zarr_root, 'store'):
            self.zarr_root.store.close()
    
    def _preload_data(self):
        """ğŸ”¥ é¢„åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®åˆ°å†…å­˜"""
        print("\n" + "="*70)
        print("é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜ï¼ˆé¿å… I/O é˜»å¡ï¼‰")
        print("="*70)
        
        self.data_cache = {}
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦åŠ è½½çš„é”®
        keys_to_load = set()
        
        # æœºå™¨äººæ•°æ®
        for i in range(self.num_robots):
            keys_to_load.add(f"robot{i}_eef_pos")
            keys_to_load.add(f"robot{i}_eef_rot_axis_angle")
            keys_to_load.add(f"robot{i}_gripper_width")
            keys_to_load.add(f"robot{i}_demo_start_pose")
        
        # ç›¸æœºå’Œè§¦è§‰æ•°æ®
        keys_to_load.update(self.camera_keys)
        keys_to_load.update(self.tactile_keys)
        
        # æ·»åŠ å…¶ä»–å¯èƒ½çš„é”®
        camera_mappings = ["camera0_rgb", "camera1_rgb"]
        tactile_mappings = [
            "camera0_left_tactile", "camera0_right_tactile",
            "camera1_left_tactile", "camera1_right_tactile"
        ]
        keys_to_load.update(camera_mappings)
        keys_to_load.update(tactile_mappings)
        
        # è¿‡æ»¤å‡ºå®é™…å­˜åœ¨çš„é”®
        existing_keys = [k for k in keys_to_load if k in self.data.keys()]
        
        print(f"éœ€è¦åŠ è½½ {len(existing_keys)} ä¸ªæ•°æ®æ•°ç»„...")
        
        # æ‰¹é‡åŠ è½½åˆ°å†…å­˜
        for key in tqdm(existing_keys, desc="åŠ è½½ä¸­", ncols=70):
            try:
                self.data_cache[key] = self.data[key][:]  # å®Œæ•´è¯»å–åˆ°å†…å­˜
            except Exception as e:
                print(f"è­¦å‘Š: åŠ è½½ {key} å¤±è´¥: {e}")
                self.data_cache[key] = None
        
        # åŠ è½½ episode ä¿¡æ¯
        self.episode_ends = self.zarr_root["meta"]["episode_ends"][:]
        
        print(f"âœ“ å·²åŠ è½½ {len(self.data_cache)} ä¸ªæ•°ç»„åˆ°å†…å­˜")
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨
        total_bytes = sum(
            arr.nbytes for arr in self.data_cache.values() 
            if arr is not None and hasattr(arr, 'nbytes')
        )
        print(f"âœ“ æ€»å†…å­˜ä½¿ç”¨: {total_bytes / 1024**3:.2f} GB")
        print("="*70)
    
    def get_episode_info(self):
        """ä»å†…å­˜ç¼“å­˜è·å– episode ä¿¡æ¯"""
        n_episodes = len(self.episode_ends)
        n_steps = self.episode_ends[-1] if len(self.episode_ends) > 0 else 0
        return n_episodes, n_steps, self.episode_ends
    
    def get_episode_slice(self, episode_idx, episode_ends):
        """è¿”å›ç»™å®š episode ç´¢å¼•çš„åˆ‡ç‰‡èŒƒå›´"""
        if episode_idx == 0:
            start_idx = 0
        else:
            start_idx = episode_ends[episode_idx - 1]
        end_idx = episode_ends[episode_idx]
        return slice(start_idx, end_idx)
    
    def analyze_zarr_structure(self):
        """åˆ†æ Zarr æ•°æ®ç»“æ„"""
        print("\n" + "="*70)
        print("åˆ†æ Zarr æ•°æ®ç»“æ„")
        print("="*70)
        print(f"\næ£€æµ‹åˆ°:")

        keys = list(self.data.keys())
        
        robot_keys = [k for k in keys if k.startswith('robot') and 'eef_pos' in k]
        num_robots = len(robot_keys)
        print(f"  - æœºå™¨äººæ•°é‡: {num_robots}")

        camera_keys = [k for k in keys if k.startswith('camera') and ('rgb' in k)]
        num_cameras = len(camera_keys)
        print(f"  - ç›¸æœºæ•°é‡: {num_cameras}")

        tactile_keys = [k for k in keys if k.startswith('camera') and ('tactile' in k)]
        num_tactiles = len(tactile_keys)
        print(f"  - è§¦è§‰ä¼ æ„Ÿå™¨æ•°é‡: {num_tactiles}")
        
        episode_ends = self.zarr_root["meta"]["episode_ends"][:]
        n_episodes = len(episode_ends)
        n_steps = episode_ends[-1] if len(episode_ends) > 0 else 0
        print(f"  - Episodes: {n_episodes}")
        print(f"  - æ€»æ­¥éª¤æ•°: {n_steps}")
        
        return robot_keys, camera_keys, tactile_keys, num_robots, num_cameras, num_tactiles
    
    def create_lerobot_dataset(self):
        """åˆ›å»º LeRobot æ•°æ®é›†ç»“æ„"""
        print(f"\nåˆ›å»º LeRobot æ•°æ®é›†:")
        print(f"  - æ•°æ®é›† ID: {self.output_repo_id}")
        print(f"  - å›¾åƒå½¢çŠ¶: {self.img_size}")
        print(f"  - çŠ¶æ€ç»´åº¦: {self.state_dim}")
        print(f"  - åŠ¨ä½œç»´åº¦: {self.action_dim}")
        print(f"  - é‡‡é›†é¢‘ç‡: {self.fps} Hz")
        
        features = {
            "observation.images.camera0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.camera1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_left_0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_right_0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_left_1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_right_1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (self.state_dim,),
                "names": ["observation.state"],
            },
            "actions": {
                "dtype": "float32",
                "shape": (self.action_dim,),
                "names": ["actions"],
            },
        }
        
        dataset = LeRobotDataset.create(
            repo_id=self.output_repo_id,
            fps=self.fps,
            robot_type="bimanual",
            features=features,
            use_videos=False,
            image_writer_threads=10,
            image_writer_processes=5,
        )
        
        return dataset
    
    def convert_all_episodes(self, episode_workers=None):
        """
        ğŸ”¥ ä¼˜åŒ–ç‰ˆï¼šé¢„åŠ è½½æ•°æ® + å¼‚æ­¥å†™å…¥
        
        Args:
            episode_workers: å¹¶è¡Œå¤„ç†çš„ episode æ•°é‡
        """
        n_episodes, n_steps, episode_ends = self.get_episode_info()
        
        print(f"\næ•°æ®ç»´åº¦:")
        print(f"  - Episodes: {n_episodes}")
        print(f"  - æ€»æ­¥éª¤æ•°: {n_steps}")
        print(f"  - å›¾åƒå½¢çŠ¶: {self.img_size}")
        print(f"  - çŠ¶æ€ç»´åº¦: {self.state_dim}")
        print(f"  - åŠ¨ä½œç»´åº¦: {self.action_dim}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = self.create_lerobot_dataset()
        
        # è®¾ç½®å¹¶è¡Œåº¦
        if episode_workers is None:
            episode_workers = min(8, os.cpu_count() or 4)
        episode_workers = max(1, min(episode_workers, n_episodes))
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ å¼€å§‹è½¬æ¢ï¼ˆä¼˜åŒ–æ¨¡å¼ï¼‰")
        print(f"{'='*70}")
        print(f"  - Episode å¹¶è¡Œåº¦: {episode_workers}")
        print(f"  - æ•°æ®æº: å†…å­˜ç¼“å­˜ï¼ˆæ—  I/O é˜»å¡ï¼‰")
        print(f"  - å†™å…¥æ¨¡å¼: å¼‚æ­¥å†™å…¥ï¼ˆè¯»å†™å¹¶è¡Œï¼‰")
        print(f"{'='*70}\n")
        
        # ğŸ”¥ å¼‚æ­¥å†™å…¥é˜Ÿåˆ—å’Œçº¿ç¨‹
        write_queue = Queue(maxsize=episode_workers * 2)
        write_complete = {'value': False}
        total_frames = {'value': 0}
        
        def writer_thread():
            """åå°å†™å…¥çº¿ç¨‹"""
            while True:
                item = write_queue.get()
                if item is None:  # ç»“æŸä¿¡å·
                    write_complete['value'] = True
                    break
                
                ep_idx, frame_list = item
                for frame_data in frame_list:
                    dataset.add_frame(frame_data)
                dataset.save_episode()
                total_frames['value'] += len(frame_list)
                write_queue.task_done()
        
        # å¯åŠ¨å†™å…¥çº¿ç¨‹
        writer = Thread(target=writer_thread, daemon=True)
        writer.start()
        
        # ğŸ”¥ å¤šçº¿ç¨‹è¯»å– + æ„å»ºå¸§æ•°æ®
        with ThreadPoolExecutor(max_workers=episode_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆä½†ä¿æŒé¡ºåºï¼‰
            future_to_idx = {
                executor.submit(self._build_episode_frames, ep_idx, episode_ends): ep_idx
                for ep_idx in range(n_episodes)
            }
            
            # æŒ‰å®Œæˆé¡ºåºæ”¶é›†ï¼Œä½†æŒ‰ episode é¡ºåºå†™å…¥
            results_by_idx = [None] * n_episodes
            
            for future in tqdm(as_completed(future_to_idx), 
                             total=n_episodes, 
                             desc="æ„å»ºå¸§æ•°æ®",
                             ncols=70):
                ep_idx = future_to_idx[future]
                try:
                    frame_list = future.result()
                    results_by_idx[ep_idx] = frame_list
                except Exception as e:
                    raise RuntimeError(f"Episode {ep_idx} å¤„ç†å¤±è´¥: {e}") from e
        
        # æŒ‰é¡ºåºæ”¾å…¥å†™å…¥é˜Ÿåˆ—
        print("\næ­£åœ¨å†™å…¥æ•°æ®é›†...")
        for ep_idx in tqdm(range(n_episodes), desc="å†™å…¥ episodes", ncols=70):
            frame_list = results_by_idx[ep_idx]
            write_queue.put((ep_idx, frame_list))
        
        # ç­‰å¾…å†™å…¥å®Œæˆ
        write_queue.join()
        write_queue.put(None)
        writer.join()
        
        print(f"\n{'='*70}")
        print(f"âœ“ è½¬æ¢å®Œæˆ!")
        print(f"{'='*70}")
        print(f"æ•°æ®é›†ä¿å­˜ä½ç½®: {dataset.root}")
        print(f"æ€» episodes: {n_episodes}")
        print(f"æ€»å¸§æ•°: {total_frames['value']}")
        print(f"å¹³å‡æ¯ä¸ª episode å¸§æ•°: {total_frames['value'] / n_episodes:.1f}")
        
        return dataset
    
    def _build_episode_frames(self, ep_idx, episode_ends):
        """
        ğŸ”¥ ä»å†…å­˜ç¼“å­˜æ„å»ºå•ä¸ª episode çš„æ‰€æœ‰å¸§ï¼ˆæ—  I/O é˜»å¡ï¼‰
        """
        episode_slice = self.get_episode_slice(ep_idx, episode_ends)
        start_idx, stop_idx = episode_slice.start, episode_slice.stop
        
        frame_list = []
        for step_idx in range(start_idx, stop_idx):
            frame_data = self._build_frame_data(step_idx, stop_idx)
            frame_list.append(frame_data)
        
        return frame_list
    
    def _build_frame_data(self, step_idx, stop_idx):
        """
        ğŸ”¥ ä»å†…å­˜ç¼“å­˜æ„å»ºå•å¸§æ•°æ®ï¼ˆæ‰€æœ‰ self.data æ”¹ä¸º self.data_cacheï¼‰
        """
        frame_data = {}
        
        # è¯­è¨€æŒ‡ä»¤
        if step_idx < len(self.language_instruction):
            frame_data["task"] = self.language_instruction[step_idx]
        else:
            frame_data["task"] = self.language_instruction[-1]

        # å›¾åƒ - ä»å†…å­˜è¯»å–
        camera_mappings = {
            "camera0_rgb": "observation.images.camera0",
            "camera1_rgb": "observation.images.camera1",
        }

        for cam_key, feature_key in camera_mappings.items():
            if cam_key in self.data_cache and self.data_cache[cam_key] is not None:
                img_data = self.data_cache[cam_key][step_idx]
                frame_data[feature_key] = self._process_image(img_data)
            else:
                frame_data[feature_key] = np.zeros((224, 224, 3), dtype=np.uint8)

        tactile_mappings = {
            "camera0_left_tactile": "observation.images.tactile_left_0",
            "camera0_right_tactile": "observation.images.tactile_right_0",
            "camera1_left_tactile": "observation.images.tactile_left_1",
            "camera1_right_tactile": "observation.images.tactile_right_1",
        }

        for tac_key, feature_key in tactile_mappings.items():
            if tac_key in self.data_cache and self.data_cache[tac_key] is not None:
                img_data = self.data_cache[tac_key][step_idx]
                frame_data[feature_key] = self._process_image(img_data)
            else:
                frame_data[feature_key] = np.zeros((224, 224, 3), dtype=np.uint8)

        # çŠ¶æ€å‘é‡ - ä»å†…å­˜è¯»å–
        state_features = []
        curr2world_mat_0 = None
        curr2world_mat_1 = None

        for i in range(self.num_robots):
            # 1. ç›¸å¯¹åˆå§‹ä½å§¿
            init_pose_key = f"robot{i}_demo_start_pose"
            if init_pose_key in self.data_cache and self.data_cache[init_pose_key] is not None:
                init2world_mat = pose_to_mat(self.data_cache[init_pose_key][0])
            else:
                init2world_mat = np.eye(4)
            
            pos_key = f"robot{i}_eef_pos"
            rot_key = f"robot{i}_eef_rot_axis_angle"
            
            if (pos_key in self.data_cache and rot_key in self.data_cache and 
                self.data_cache[pos_key] is not None and self.data_cache[rot_key] is not None):
                curr2world_mat = pose_to_mat(
                    np.concatenate([
                        self.data_cache[pos_key][step_idx],
                        self.data_cache[rot_key][step_idx],
                    ], axis=-1)
                )
            else:
                curr2world_mat = np.eye(4)
            
            if i == 0:
                curr2world_mat_0 = curr2world_mat
            else:
                curr2world_mat_1 = curr2world_mat

            curr2init_mat = np.linalg.inv(init2world_mat) @ curr2world_mat
            curr2init_pose = mat_to_pose(curr2init_mat)
            state_features.extend(curr2init_pose)

            # 2. å¤¹çˆªè·ç¦»
            grip_key = f"robot{i}_gripper_width"
            if grip_key in self.data_cache and self.data_cache[grip_key] is not None:
                grip_data = self.data_cache[grip_key][step_idx]
                try:
                    if hasattr(grip_data, "__len__"):
                        state_features.append(float(grip_data[0]))
                    else:
                        state_features.append(float(grip_data))
                except Exception:
                    state_features.append(0.0)
            else:
                state_features.append(0.0)

        # 3. ä¸¤ä¸ªæœ«ç«¯æ‰§è¡Œå™¨ç›¸å¯¹ä½å§¿
        if curr2world_mat_0 is not None and curr2world_mat_1 is not None:
            rel_0to1_pose = mat_to_pose(
                np.linalg.inv(curr2world_mat_1) @ curr2world_mat_0
            )
            state_features.extend(rel_0to1_pose)

        # ç»´åº¦è°ƒæ•´
        expected_state_dim = self.state_dim
        if len(state_features) < expected_state_dim:
            state_features.extend([0.0] * (expected_state_dim - len(state_features)))
        elif len(state_features) > expected_state_dim:
            state_features = state_features[:expected_state_dim]

        frame_data["observation.state"] = np.asarray(state_features, dtype=np.float32)

        # åŠ¨ä½œï¼ˆå˜åŒ–é‡ï¼‰- ä»å†…å­˜è¯»å–
        if step_idx < stop_idx - 1:
            action_features = []
            for i in range(self.num_robots):
                pos_key = f"robot{i}_eef_pos"
                rot_key = f"robot{i}_eef_rot_axis_angle"
                
                if (pos_key in self.data_cache and rot_key in self.data_cache and
                    self.data_cache[pos_key] is not None and self.data_cache[rot_key] is not None):
                    next2world_mat = pose_to_mat(
                        np.concatenate([
                            self.data_cache[pos_key][step_idx + 1],
                            self.data_cache[rot_key][step_idx + 1],
                        ], axis=-1)
                    )
                    curr2world_mat = pose_to_mat(
                        np.concatenate([
                            self.data_cache[pos_key][step_idx],
                            self.data_cache[rot_key][step_idx],
                        ], axis=-1)
                    )

                    next2curr_mat = np.linalg.inv(curr2world_mat) @ next2world_mat
                    next2curr_pos = mat_to_pose(next2curr_mat)[:3]
                    rot_cols = next2curr_mat[:3, :2].reshape(-1)
                    action_feature_9d = np.concatenate([next2curr_pos, rot_cols], axis=0)
                    action_features.extend(action_feature_9d)
                else:
                    action_features.extend([0.0] * 9)

                # Î” gripper
                grip_key = f"robot{i}_gripper_width"
                if grip_key in self.data_cache and self.data_cache[grip_key] is not None:
                    next_grip = self.data_cache[grip_key][step_idx + 1]
                    curr_grip = self.data_cache[grip_key][step_idx]
                    try:
                        if hasattr(next_grip, "__len__") and hasattr(curr_grip, "__len__"):
                            delta_grip = float(next_grip[0] - curr_grip[0])
                        elif hasattr(next_grip, "__len__"):
                            delta_grip = float(next_grip[0] - curr_grip)
                        elif hasattr(curr_grip, "__len__"):
                            delta_grip = float(next_grip - curr_grip[0])
                        else:
                            delta_grip = float(next_grip - curr_grip)
                        action_features.append(delta_grip)
                    except Exception:
                        action_features.append(0.0)
                else:
                    action_features.append(0.0)

            frame_data["actions"] = np.asarray(action_features, dtype=np.float32)
        else:
            action_dim = self.action_dim
            frame_data["actions"] = np.zeros(action_dim, dtype=np.float32)

        return frame_data
    
    def _process_image(self, image_data, target_h=224, target_w=224):
        """å¤„ç†å›¾åƒæ•°æ®ï¼šè§£ç å¹¶è°ƒæ•´å¤§å°"""
        if isinstance(image_data, bytes):
            img = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            else:
                img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        elif hasattr(image_data, "shape"):
            img = image_data
            if len(img.shape) == 3 and img.shape[2] == 3:
                pass
            elif len(img.shape) == 2:
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        else:
            img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        
        if img.dtype == np.uint8:
            pass
        elif img.dtype in [np.float32, np.float64]:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            else:
                img = np.clip(img, 0, 255).astype(np.uint8)
        else:
            img = img.astype(np.uint8)
        
        try:
            img = cv2.resize(img, (target_w, target_h))
        except Exception:
            img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        
        return img


def main(data_name="_0118"):
    parser = argparse.ArgumentParser(
        description='è½¬æ¢ ViTaMin-B Zarr æ•°æ®åˆ° LeRobot æ ¼å¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--zarr_path',
        type=str,
        default=f'data/{data_name}.zarr.zip',
        help='Zarr æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--repo_id',
        type=str,
        default=f'data/lerobot/chaoyi/{data_name}',
        help='LeRobot æ•°æ®é›† ID'
    )
    parser.add_argument(
        '--fps',
        type=int,
        default=30,
        help='æ•°æ®é‡‡é›†é¢‘ç‡ (Hz)'
    )
    parser.add_argument(
        '--language_instruction',
        type=str,
        default=["perform bimanual manipulation task"],
        help='ä»»åŠ¡æè¿°'
    )
    parser.add_argument(
        '--episode_workers',
        type=int,
        default=None,
        help='å¹¶è¡Œå¤„ç†çš„ episode æ•°é‡'
    )
    
    args = parser.parse_args()
    
    zarr_path = Path(args.zarr_path)
    if not zarr_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ° Zarr æ–‡ä»¶: {zarr_path}")
        sys.exit(1)
    
    print("="*70)
    print("ViTaMin-B Zarr â†’ LeRobot è½¬æ¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("="*70)
    print(f"Zarr æ–‡ä»¶: {zarr_path.absolute()}")
    print(f"ç›®æ ‡æ•°æ®é›†: {args.repo_id}")
    print(f"é‡‡é›†é¢‘ç‡: {args.fps} Hz")
    print("="*70)
    print()
    
    try:
        converter = ZarrToLeRobotConverter(
            zarr_path=args.zarr_path,
            output_repo_id=args.repo_id,
            fps=args.fps,
            state_dim=20,
            action_dim=20,
            language_instruction=args.language_instruction
        )
        
        dataset = converter.convert_all_episodes(
            episode_workers=args.episode_workers,
        )
        
    except Exception as e:
        print(f"\né”™è¯¯: è½¬æ¢å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main(data_name="example")
#!/usr/bin/env python3
"""
å°† ViTaMin-B Zarr æ ¼å¼æ•°æ®è½¬æ¢ä¸º LeRobot æ ¼å¼ï¼ˆå†…å­˜èŠ‚çº¦ç‰ˆï¼šè¿›ç¨‹æ±  + æ‰¹é‡è¯»å–ï¼‰
"""

import argparse
import sys
import os
from pathlib import Path
from multiprocessing import Pool, cpu_count
import numpy as np
import cv2
from tqdm import tqdm

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.append(project_root)

import zarr
from zarr.storage import ZipStore
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

# æ³¨å†Œå›¾åƒè§£ç å™¨
from utils.imagecodecs_numcodecs import register_codecs
register_codecs()
from utils.pose_util import pose_to_mat, mat_to_pose


# ============================================================================
# è¿›ç¨‹æ± å…¨å±€å˜é‡ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹çš„ storeï¼‰
# ============================================================================
_PROCESS_ZARR_ROOT = None
_PROCESS_DATA = None


def _worker_init(zarr_path):
    """
    ğŸ”¥ è¿›ç¨‹æ± åˆå§‹åŒ–å‡½æ•°ï¼šæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹æ‰“å¼€è‡ªå·±çš„ ZipStore
    é¿å…å¤šè¿›ç¨‹å…±äº«åŒä¸€ä¸ªæ–‡ä»¶å¥æŸ„å¯¼è‡´çš„é”äº‰ç”¨
    """
    global _PROCESS_ZARR_ROOT, _PROCESS_DATA
    
    # æ¯ä¸ªè¿›ç¨‹æ‰“å¼€è‡ªå·±çš„åªè¯» store
    store = ZipStore(zarr_path, mode="r")
    _PROCESS_ZARR_ROOT = zarr.open_group(store=store, mode="r")
    _PROCESS_DATA = _PROCESS_ZARR_ROOT["data"]
    
    # é‡æ–°æ³¨å†Œç¼–è§£ç å™¨ï¼ˆæ¯ä¸ªè¿›ç¨‹éœ€è¦ç‹¬ç«‹æ³¨å†Œï¼‰
    register_codecs()


def _build_episode_frames_worker(args):
    """
    ğŸ”¥ è¿›ç¨‹æ±  workerï¼šæ‰¹é‡è¯»å–å•ä¸ª episode çš„æ•°æ®å¹¶æ„å»ºæ‰€æœ‰å¸§
    
    è¿™ä¸ªå‡½æ•°å¿…é¡»æ˜¯æ¨¡å—çº§å‡½æ•°ï¼ˆä¸èƒ½æ˜¯ç±»æ–¹æ³•ï¼‰ï¼Œå› ä¸º multiprocessing éœ€è¦ pickle
    """
    (ep_idx, start_idx, stop_idx, num_robots, state_dim, action_dim, 
     language_instruction, img_size) = args
    
    global _PROCESS_DATA
    
    # ========================================================================
    # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šæ‰¹é‡è¯»å–è¯¥ episode çš„æ‰€æœ‰æ•°æ®åˆ‡ç‰‡ï¼ˆä¸€æ¬¡ I/Oï¼‰
    # ========================================================================
    episode_data = {}
    
    # éœ€è¦è¯»å–çš„æ‰€æœ‰é”®
    keys_to_load = []
    
    # æœºå™¨äººæ•°æ®
    for i in range(num_robots):
        keys_to_load.extend([
            f"robot{i}_eef_pos",
            f"robot{i}_eef_rot_axis_angle",
            f"robot{i}_gripper_width",
            f"robot{i}_demo_start_pose",
        ])
    
    # ç›¸æœºå’Œè§¦è§‰æ•°æ®
    camera_keys = ["camera0_rgb", "camera1_rgb"]
    tactile_keys = [
        "camera0_left_tactile", "camera0_right_tactile",
        "camera1_left_tactile", "camera1_right_tactile"
    ]
    keys_to_load.extend(camera_keys)
    keys_to_load.extend(tactile_keys)
    
    # æ‰¹é‡åˆ‡ç‰‡è¯»å–ï¼ˆå…³é”®ï¼šä¸€æ¬¡è¯»å–æ•´ä¸ª episode èŒƒå›´ï¼Œè€Œä¸æ˜¯é€å¸§è¯»å–ï¼‰
    for key in keys_to_load:
        if key in _PROCESS_DATA.keys():
            try:
                # åªè¯»å–å½“å‰ episode çš„æ•°æ®èŒƒå›´
                if key.endswith('_demo_start_pose'):
                    # demo_start_pose åªéœ€è¦ç¬¬ä¸€ä¸ªå€¼
                    episode_data[key] = _PROCESS_DATA[key][0:1]
                else:
                    episode_data[key] = _PROCESS_DATA[key][start_idx:stop_idx]
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å– {key} å¤±è´¥: {e}")
                episode_data[key] = None
        else:
            episode_data[key] = None
    
    # ========================================================================
    # åŸºäºæ‰¹é‡è¯»å–çš„æ•°æ®æ„å»ºæ‰€æœ‰å¸§ï¼ˆçº¯å†…å­˜æ“ä½œï¼Œæ—  I/Oï¼‰
    # ========================================================================
    frame_list = []
    episode_length = stop_idx - start_idx
    
    for local_idx in range(episode_length):
        global_idx = start_idx + local_idx
        
        frame_data = _build_single_frame(
            episode_data=episode_data,
            local_idx=local_idx,
            global_idx=global_idx,
            episode_length=episode_length,
            num_robots=num_robots,
            state_dim=state_dim,
            action_dim=action_dim,
            language_instruction=language_instruction,
            img_size=img_size
        )
        
        frame_list.append(frame_data)
    
    return ep_idx, frame_list


def _build_single_frame(episode_data, local_idx, global_idx, episode_length,
                        num_robots, state_dim, action_dim, language_instruction, img_size):
    """
    ä»æ‰¹é‡è¯»å–çš„ episode æ•°æ®ä¸­æ„å»ºå•å¸§ï¼ˆçº¯å†…å­˜æ“ä½œï¼‰
    
    Args:
        episode_data: è¯¥ episode çš„æ‰€æœ‰æ•°æ®ï¼ˆå·²æ‰¹é‡è¯»å–ï¼‰
        local_idx: åœ¨ episode å†…çš„ç´¢å¼•ï¼ˆ0-basedï¼‰
        global_idx: å…¨å±€ç´¢å¼•ï¼ˆç”¨äº language_instructionï¼‰
        episode_length: episode æ€»å¸§æ•°
        å…¶ä»–å‚æ•°: é…ç½®ä¿¡æ¯
    """
    frame_data = {}
    
    # è¯­è¨€æŒ‡ä»¤
    if global_idx < len(language_instruction):
        frame_data["task"] = language_instruction[global_idx]
    else:
        frame_data["task"] = language_instruction[-1]
    
    # ========================================================================
    # å›¾åƒæ•°æ®
    # ========================================================================
    camera_mappings = {
        "camera0_rgb": "observation.images.camera0",
        "camera1_rgb": "observation.images.camera1",
    }
    
    for cam_key, feature_key in camera_mappings.items():
        if cam_key in episode_data and episode_data[cam_key] is not None:
            img_data = episode_data[cam_key][local_idx]
            frame_data[feature_key] = _process_image(img_data, img_size)
        else:
            frame_data[feature_key] = np.zeros(img_size, dtype=np.uint8)
    
    tactile_mappings = {
        "camera0_left_tactile": "observation.images.tactile_left_0",
        "camera0_right_tactile": "observation.images.tactile_right_0",
        "camera1_left_tactile": "observation.images.tactile_left_1",
        "camera1_right_tactile": "observation.images.tactile_right_1",
    }
    
    for tac_key, feature_key in tactile_mappings.items():
        if tac_key in episode_data and episode_data[tac_key] is not None:
            img_data = episode_data[tac_key][local_idx]
            frame_data[feature_key] = _process_image(img_data, img_size)
        else:
            frame_data[feature_key] = np.zeros(img_size, dtype=np.uint8)
    
    # ========================================================================
    # çŠ¶æ€å‘é‡
    # ========================================================================
    state_features = []
    curr2world_mat_0 = None
    curr2world_mat_1 = None
    
    for i in range(num_robots):
        # 1. ç›¸å¯¹åˆå§‹ä½å§¿
        init_pose_key = f"robot{i}_demo_start_pose"
        if init_pose_key in episode_data and episode_data[init_pose_key] is not None:
            init2world_mat = pose_to_mat(episode_data[init_pose_key][0])
        else:
            init2world_mat = np.eye(4)
        
        pos_key = f"robot{i}_eef_pos"
        rot_key = f"robot{i}_eef_rot_axis_angle"
        
        if (pos_key in episode_data and rot_key in episode_data and
            episode_data[pos_key] is not None and episode_data[rot_key] is not None):
            curr2world_mat = pose_to_mat(
                np.concatenate([
                    episode_data[pos_key][local_idx],
                    episode_data[rot_key][local_idx],
                ], axis=-1)
            )
        else:
            curr2world_mat = np.eye(4)
        
        if i == 0:
            curr2world_mat_0 = curr2world_mat
        else:
            curr2world_mat_1 = curr2world_mat
        
        curr2init_mat = np.linalg.inv(init2world_mat) @ curr2world_mat
        curr2init_pose = mat_to_pose(curr2init_mat)
        state_features.extend(curr2init_pose)
        
        # 2. å¤¹çˆªè·ç¦»
        grip_key = f"robot{i}_gripper_width"
        if grip_key in episode_data and episode_data[grip_key] is not None:
            grip_data = episode_data[grip_key][local_idx]
            try:
                if hasattr(grip_data, "__len__"):
                    state_features.append(float(grip_data[0]))
                else:
                    state_features.append(float(grip_data))
            except Exception:
                state_features.append(0.0)
        else:
            state_features.append(0.0)
    
    # 3. ä¸¤ä¸ªæœ«ç«¯æ‰§è¡Œå™¨ç›¸å¯¹ä½å§¿
    if curr2world_mat_0 is not None and curr2world_mat_1 is not None:
        rel_0to1_pose = mat_to_pose(
            np.linalg.inv(curr2world_mat_1) @ curr2world_mat_0
        )
        state_features.extend(rel_0to1_pose)
    
    # ç»´åº¦è°ƒæ•´
    if len(state_features) < state_dim:
        state_features.extend([0.0] * (state_dim - len(state_features)))
    elif len(state_features) > state_dim:
        state_features = state_features[:state_dim]
    
    frame_data["observation.state"] = np.asarray(state_features, dtype=np.float32)
    
    # ========================================================================
    # åŠ¨ä½œå‘é‡
    # ========================================================================
    if local_idx < episode_length - 1:
        action_features = []
        for i in range(num_robots):
            pos_key = f"robot{i}_eef_pos"
            rot_key = f"robot{i}_eef_rot_axis_angle"
            
            if (pos_key in episode_data and rot_key in episode_data and
                episode_data[pos_key] is not None and episode_data[rot_key] is not None):
                next2world_mat = pose_to_mat(
                    np.concatenate([
                        episode_data[pos_key][local_idx + 1],
                        episode_data[rot_key][local_idx + 1],
                    ], axis=-1)
                )
                curr2world_mat = pose_to_mat(
                    np.concatenate([
                        episode_data[pos_key][local_idx],
                        episode_data[rot_key][local_idx],
                    ], axis=-1)
                )
                
                next2curr_mat = np.linalg.inv(curr2world_mat) @ next2world_mat
                next2curr_pos = mat_to_pose(next2curr_mat)[:3]
                rot_cols = next2curr_mat[:3, :2].reshape(-1)
                action_feature_9d = np.concatenate([next2curr_pos, rot_cols], axis=0)
                action_features.extend(action_feature_9d)
            else:
                action_features.extend([0.0] * 9)
            
            # Î” gripper
            grip_key = f"robot{i}_gripper_width"
            if grip_key in episode_data and episode_data[grip_key] is not None:
                next_grip = episode_data[grip_key][local_idx + 1]
                curr_grip = episode_data[grip_key][local_idx]
                try:
                    if hasattr(next_grip, "__len__") and hasattr(curr_grip, "__len__"):
                        delta_grip = float(next_grip[0] - curr_grip[0])
                    elif hasattr(next_grip, "__len__"):
                        delta_grip = float(next_grip[0] - curr_grip)
                    elif hasattr(curr_grip, "__len__"):
                        delta_grip = float(next_grip - curr_grip[0])
                    else:
                        delta_grip = float(next_grip - curr_grip)
                    action_features.append(delta_grip)
                except Exception:
                    action_features.append(0.0)
            else:
                action_features.append(0.0)
        
        frame_data["actions"] = np.asarray(action_features, dtype=np.float32)
    else:
        frame_data["actions"] = np.zeros(action_dim, dtype=np.float32)
    
    return frame_data


def _process_image(image_data, img_size, target_h=224, target_w=224):
    """å¤„ç†å›¾åƒæ•°æ®"""
    if isinstance(image_data, bytes):
        img = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        else:
            img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    elif hasattr(image_data, "shape"):
        img = image_data
        if len(img.shape) == 3 and img.shape[2] == 3:
            pass
        elif len(img.shape) == 2:
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    else:
        img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    
    if img.dtype == np.uint8:
        pass
    elif img.dtype in [np.float32, np.float64]:
        if img.max() <= 1.0:
            img = (img * 255).astype(np.uint8)
        else:
            img = np.clip(img, 0, 255).astype(np.uint8)
    else:
        img = img.astype(np.uint8)
    
    try:
        img = cv2.resize(img, (target_w, target_h))
    except Exception:
        img = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    
    return img


# ============================================================================
# ä¸»è½¬æ¢å™¨ç±»
# ============================================================================
class ZarrToLeRobotConverter:
    """ViTaMin-B Zarr æ ¼å¼åˆ° LeRobot æ ¼å¼çš„è½¬æ¢å™¨ï¼ˆå†…å­˜èŠ‚çº¦ç‰ˆï¼‰"""
    
    def __init__(self, 
                 zarr_path, 
                 output_repo_id, 
                 fps=30, 
                 state_dim=20, 
                 action_dim=20,
                 language_instruction=["perform bimanual manipulation task"]):
        """åˆå§‹åŒ–è½¬æ¢å™¨ï¼ˆä»…åˆ†æç»“æ„ï¼Œä¸åŠ è½½æ•°æ®ï¼‰"""
        self.zarr_path = Path(zarr_path)
        self.output_repo_id = output_repo_id
        
        if not self.zarr_path.exists():
            raise ValueError(f"Zarr æ–‡ä»¶ä¸å­˜åœ¨: {self.zarr_path}")
        
        # ä¸´æ—¶æ‰“å¼€ store ç”¨äºåˆ†æç»“æ„
        print(f"åˆ†æ Zarr æ•°æ®ç»“æ„: {self.zarr_path}")
        store = ZipStore(self.zarr_path, mode="r")
        self.zarr_root = zarr.open_group(store=store, mode="r")
        self.data = self.zarr_root["data"]
        
        # åˆ†æç»“æ„
        self.analyze_zarr_structure()
        
        # è·å–å›¾åƒå½¢çŠ¶
        self.img_size = (224, 224, 3)
        if len(self.camera_keys) > 0:
            first_camera_rgb = _process_image(self.data[self.camera_keys[0]][0], (224, 224, 3))
            self.img_size = first_camera_rgb.shape
        
        # å…³é—­ä¸´æ—¶ storeï¼ˆè¿›ç¨‹æ± ä¼šé‡æ–°æ‰“å¼€ï¼‰
        store.close()
        
        self.fps = fps
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.language_instruction = language_instruction
    
    def analyze_zarr_structure(self):
        """åˆ†æ Zarr æ•°æ®ç»“æ„"""
        print("\n" + "="*70)
        print("åˆ†æ Zarr æ•°æ®ç»“æ„")
        print("="*70)
        
        keys = list(self.data.keys())
        
        # æ£€æµ‹æœºå™¨äººæ•°é‡
        self.robot_keys = [k for k in keys if k.startswith('robot') and 'eef_pos' in k]
        self.num_robots = len(self.robot_keys)
        print(f"  - æœºå™¨äººæ•°é‡: {self.num_robots}")
        
        # æ£€æµ‹ç›¸æœºæ•°é‡
        self.camera_keys = [k for k in keys if k.startswith('camera') and ('rgb' in k)]
        self.num_cameras = len(self.camera_keys)
        print(f"  - ç›¸æœºæ•°é‡: {self.num_cameras}")
        
        # æ£€æµ‹è§¦è§‰ä¼ æ„Ÿå™¨æ•°é‡
        self.tactile_keys = [k for k in keys if k.startswith('camera') and ('tactile' in k)]
        self.num_tactiles = len(self.tactile_keys)
        print(f"  - è§¦è§‰ä¼ æ„Ÿå™¨æ•°é‡: {self.num_tactiles}")
        
        # è·å– episode ä¿¡æ¯
        self.episode_ends = self.zarr_root["meta"]["episode_ends"][:]
        n_episodes = len(self.episode_ends)
        n_steps = self.episode_ends[-1] if len(self.episode_ends) > 0 else 0
        print(f"  - Episodes: {n_episodes}")
        print(f"  - æ€»æ­¥éª¤æ•°: {n_steps}")
        print("="*70)
    
    def create_lerobot_dataset(self):
        """åˆ›å»º LeRobot æ•°æ®é›†ç»“æ„"""
        print(f"\nåˆ›å»º LeRobot æ•°æ®é›†:")
        print(f"  - æ•°æ®é›† ID: {self.output_repo_id}")
        print(f"  - å›¾åƒå½¢çŠ¶: {self.img_size}")
        print(f"  - çŠ¶æ€ç»´åº¦: {self.state_dim}")
        print(f"  - åŠ¨ä½œç»´åº¦: {self.action_dim}")
        print(f"  - é‡‡é›†é¢‘ç‡: {self.fps} Hz")
        
        features = {
            "observation.images.camera0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.camera1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_left_0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_right_0": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_left_1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.images.tactile_right_1": {
                "dtype": "image",
                "shape": self.img_size,
                "names": ["height", "width", "channel"],
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (self.state_dim,),
                "names": ["observation.state"],
            },
            "actions": {
                "dtype": "float32",
                "shape": (self.action_dim,),
                "names": ["actions"],
            },
        }
        
        dataset = LeRobotDataset.create(
            repo_id=self.output_repo_id,
            fps=self.fps,
            robot_type="bimanual",
            features=features,
            use_videos=False,
            image_writer_threads=10,
            image_writer_processes=5,
        )
        
        return dataset
    
    def convert_all_episodes(self, num_workers=None):
        """
        ğŸ”¥ ä½¿ç”¨è¿›ç¨‹æ±  + æ‰¹é‡è¯»å–è½¬æ¢æ‰€æœ‰ episodes
        
        Args:
            num_workers: è¿›ç¨‹æ± å¤§å°ï¼ŒNone æ—¶è‡ªåŠ¨è®¾ç½®
        """
        n_episodes = len(self.episode_ends)
        n_steps = self.episode_ends[-1] if len(self.episode_ends) > 0 else 0
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ å¼€å§‹è½¬æ¢ï¼ˆå†…å­˜èŠ‚çº¦æ¨¡å¼ï¼‰")
        print(f"{'='*70}")
        print(f"  - Episodes: {n_episodes}")
        print(f"  - æ€»æ­¥éª¤æ•°: {n_steps}")
        print(f"  - è½¬æ¢ç­–ç•¥: è¿›ç¨‹æ±  + æŒ‰ episode æ‰¹é‡è¯»å–")
        
        # è®¾ç½®è¿›ç¨‹æ•°
        if num_workers is None:
            num_workers = min(4, cpu_count() or 4)
        num_workers = max(1, min(num_workers, n_episodes))
        
        print(f"  - è¿›ç¨‹æ•°: {num_workers}")
        print(f"{'='*70}\n")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = self.create_lerobot_dataset()
        
        # å‡†å¤‡å‚æ•°åˆ—è¡¨
        args_list = []
        for ep_idx in range(n_episodes):
            if ep_idx == 0:
                start_idx = 0
            else:
                start_idx = self.episode_ends[ep_idx - 1]
            stop_idx = self.episode_ends[ep_idx]
            
            args_list.append((
                ep_idx,
                start_idx,
                stop_idx,
                self.num_robots,
                self.state_dim,
                self.action_dim,
                self.language_instruction,
                self.img_size
            ))
        
        # ====================================================================
        # ğŸ”¥ ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ storeï¼Œæ‰¹é‡è¯»å– episodeï¼‰
        # ====================================================================
        print("ä½¿ç”¨è¿›ç¨‹æ± å¤„ç† episodes...")
        results_by_idx = [None] * n_episodes
        
        with Pool(processes=num_workers, 
                  initializer=_worker_init, 
                  initargs=(str(self.zarr_path),)) as pool:
            
            # ä½¿ç”¨ imap_unordered æé«˜æ•ˆç‡ï¼ˆç»“æœæ— åºï¼Œä½†æˆ‘ä»¬ä¼šé‡æ’ï¼‰
            for ep_idx, frame_list in tqdm(
                pool.imap_unordered(_build_episode_frames_worker, args_list),
                total=n_episodes,
                desc="è½¬æ¢ episodes",
                ncols=70
            ):
                results_by_idx[ep_idx] = frame_list
        
        # ====================================================================
        # ä¸»è¿›ç¨‹æŒ‰é¡ºåºå†™å…¥ dataset
        # ====================================================================
        print("\nå†™å…¥æ•°æ®é›†...")
        total_frames = 0
        
        for ep_idx in tqdm(range(n_episodes), desc="ä¿å­˜ episodes", ncols=70):
            frame_list = results_by_idx[ep_idx]
            for frame_data in frame_list:
                dataset.add_frame(frame_data)
            dataset.save_episode()
            total_frames += len(frame_list)
        
        print(f"\n{'='*70}")
        print(f"âœ“ è½¬æ¢å®Œæˆ!")
        print(f"{'='*70}")
        print(f"æ•°æ®é›†ä¿å­˜ä½ç½®: {dataset.root}")
        print(f"æ€» episodes: {n_episodes}")
        print(f"æ€»å¸§æ•°: {total_frames}")
        print(f"å¹³å‡æ¯ä¸ª episode å¸§æ•°: {total_frames / n_episodes:.1f}")
        
        return dataset


def main(data_name="_0118"):
    parser = argparse.ArgumentParser(
        description='è½¬æ¢ ViTaMin-B Zarr æ•°æ®åˆ° LeRobot æ ¼å¼ï¼ˆå†…å­˜èŠ‚çº¦ç‰ˆï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--zarr_path',
        type=str,
        default=f'data/{data_name}.zarr.zip',
        help='Zarr æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--repo_id',
        type=str,
        default=f'chaoyi/{data_name}',
        help='LeRobot æ•°æ®é›† ID'
    )
    parser.add_argument(
        '--fps',
        type=int,
        default=30,
        help='æ•°æ®é‡‡é›†é¢‘ç‡ (Hz)'
    )
    parser.add_argument(
        '--language_instruction',
        type=str,
        default=["perform bimanual manipulation task"],
        help='ä»»åŠ¡æè¿°'
    )
    parser.add_argument(
        '--num_workers',
        type=int,
        default=None,
        help='è¿›ç¨‹æ± å¤§å°ï¼ˆé»˜è®¤ min(4, CPUæ ¸å¿ƒæ•°)ï¼‰'
    )
    
    args = parser.parse_args()
    
    zarr_path = Path(args.zarr_path)
    if not zarr_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ° Zarr æ–‡ä»¶: {zarr_path}")
        sys.exit(1)
    
    print("="*70)
    print("ViTaMin-B Zarr â†’ LeRobot è½¬æ¢ï¼ˆå†…å­˜èŠ‚çº¦ç‰ˆï¼‰")
    print("="*70)
    print(f"Zarr æ–‡ä»¶: {zarr_path.absolute()}")
    print(f"ç›®æ ‡æ•°æ®é›†: {args.repo_id}")
    print(f"é‡‡é›†é¢‘ç‡: {args.fps} Hz")
    print("="*70)
    print()
    
    try:
        converter = ZarrToLeRobotConverter(
            zarr_path=args.zarr_path,
            output_repo_id=args.repo_id,
            fps=args.fps,
            state_dim=20,
            action_dim=20,
            language_instruction=args.language_instruction
        )
        
        dataset = converter.convert_all_episodes(
            num_workers=args.num_workers,
        )
        
    except Exception as e:
        print(f"\né”™è¯¯: è½¬æ¢å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main(data_name="example")